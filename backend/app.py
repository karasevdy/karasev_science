from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from collections import defaultdict

app = Flask(__name__)

CORS(app, resources={
    r"/*": {
        "origins": [
            "https://karasevdy.github.io",  # —Ç–≤–æ–π GitHub Pages
            "https://*.github.io",  # –≤—Å–µ –ø–æ–¥–¥–æ–º–µ–Ω—ã github.io
            "http://localhost:*",  # –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
            "http://127.0.0.1:*"
        ]
    }
})

# ============================================
# –ó–ê–ì–†–£–ó–ö–ê ML –ú–û–î–ï–õ–ò
# ============================================
MODEL_LOADED = False
PANDAS_LOADED = False
SKLEARN_LOADED = False
model = None
np = None
pd = None

try:
    from catboost import CatBoostClassifier
    import numpy as np_module

    np = np_module
    model = CatBoostClassifier()
    model.load_model('catboost_model_4_08_08_25.json')
    print("‚úÖ –ú–æ–¥–µ–ª—å CatBoost –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    MODEL_LOADED = True
except ImportError as e:
    print(f"‚ö†Ô∏è CatBoost –∏–ª–∏ NumPy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
except Exception as e:
    print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {e}")

try:
    import pandas as pd_module

    pd = pd_module
    print("‚úÖ Pandas —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    PANDAS_LOADED = True
except ImportError:
    print("‚ùå Pandas –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")

try:
    from sklearn.metrics import precision_recall_fscore_support
    from sklearn.preprocessing import StandardScaler

    SKLEARN_LOADED = True
    print("‚úÖ sklearn —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
except ImportError:
    print("‚ö†Ô∏è sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


# ============================================
# ROOT ENDPOINT
# ============================================

@app.route('/')
def index():
    """API –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"""
    return jsonify({
        'status': 'ok',
        'message': 'Legislative Behaviour Modeling API',
        'version': '1.0',
        'endpoints': {
            'health': '/api/health',
            'deputies_list': '/api/deputies/list',
            'votings_list': '/api/votings_list',
            'predict': '/api/predict (POST)',
            'predict_all': '/api/predict_all (POST)',
            'simulate': '/api/simulate (POST)',
            'predict_voting': '/api/predict_voting/<voting_id> (POST)',
            'graph_real': '/api/graph/real/<deputy_name>',
            'graph_coauthorship': '/api/graph/coauthorship'
        },
        'models': {
            'catboost_loaded': MODEL_LOADED,
            'pandas_loaded': PANDAS_LOADED,
            'sklearn_loaded': SKLEARN_LOADED
        }
    })


# ============================================
# API ENDPOINTS - HEALTH CHECK
# ============================================

@app.route('/api/health', methods=['GET'])
def health():
    return jsonify({
        'status': 'ok',
        'model_loaded': MODEL_LOADED,
        'pandas_loaded': PANDAS_LOADED,
        'sklearn_loaded': SKLEARN_LOADED
    })


# ============================================
# API ENDPOINTS - ML MODEL
# ============================================

@app.route('/api/predict', methods=['POST'])
def predict():
    if not MODEL_LOADED:
        return jsonify({'success': False, 'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}), 503

    try:
        data = request.get_json()
        features = data.get('features', [])

        if len(features) != 42:
            return jsonify({'success': False, 'error': f'–ù—É–∂–Ω–æ 42 –ø—Ä–∏–∑–Ω–∞–∫–∞, –ø–æ–ª—É—á–µ–Ω–æ {len(features)}'}), 400

        features_array = np.array(features, dtype=np.float64).reshape(1, -1)
        prediction = model.predict(features_array)
        proba = model.predict_proba(features_array)

        vote_classes = ['–ó–∞', '–ü—Ä–æ—Ç–∏–≤', '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è', '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª', '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª']

        predicted_class = int(prediction.flatten()[0])
        probabilities_array = proba.flatten()

        probabilities = {}
        for i in range(min(len(vote_classes), len(probabilities_array))):
            probabilities[vote_classes[i]] = float(probabilities_array[i])

        confidence = float(max(probabilities_array)) * 100

        return jsonify({
            'success': True,
            'prediction': vote_classes[predicted_class] if predicted_class < len(vote_classes) else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
            'prediction_code': predicted_class,
            'probabilities': probabilities,
            'confidence': confidence
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/deputies', methods=['GET'])
def get_deputies():
    if not PANDAS_LOADED:
        return jsonify({'success': False, 'error': 'Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}), 500

    try:
        X_path = '../data/X_2273_94008.csv'
        y_path = '../data/y_2273_94008.csv'

        if not os.path.exists(X_path):
            return jsonify({'success': False, 'error': f'–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {X_path}'}), 404

        if not os.path.exists(y_path):
            return jsonify({'success': False, 'error': f'–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {y_path}'}), 404

        X = pd.read_csv(X_path)
        y = pd.read_csv(y_path)

        deputies = []
        for idx in range(len(X)):
            fio = X.iloc[idx]['fio']
            faction = X.iloc[idx]['fr_8']
            features = X.iloc[idx].drop(['fio', 'fr_8']).values.tolist()

            if 'vote' in y.columns:
                vote = int(y.iloc[idx]['vote'])
            else:
                vote = int(y.iloc[idx, -1])

            deputies.append({
                'index': idx,
                'name': fio,
                'faction': faction,
                'features': features,
                'real_vote': vote
            })

        return jsonify({
            'success': True,
            'deputies': deputies,
            'count': len(deputies)
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–µ–ø—É—Ç–∞—Ç–æ–≤: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/predict_all', methods=['POST'])
def predict_all():
    if not MODEL_LOADED or not PANDAS_LOADED:
        return jsonify({'success': False, 'error': '–ú–æ–¥–µ–ª—å –∏–ª–∏ Pandas –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}), 503

    try:
        X_path = '../data/X_2273_94008.csv'
        y_path = '../data/y_2273_94008.csv'

        if not os.path.exists(X_path) or not os.path.exists(y_path):
            return jsonify({'success': False, 'error': '–§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'}), 404

        X = pd.read_csv(X_path)
        y = pd.read_csv(y_path)

        fio_list = X['fio'].tolist()
        faction_list = X['fr_8'].tolist()

        X_features = X.drop(columns=['fio', 'fr_8']).fillna(0)

        predictions = model.predict(X_features.values)
        probabilities = model.predict_proba(X_features.values)

        vote_classes = ['–ó–∞', '–ü—Ä–æ—Ç–∏–≤', '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è', '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª', '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª']

        results = []
        real_counts = {'–ó–∞': 0, '–ü—Ä–æ—Ç–∏–≤': 0, '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è': 0, '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª': 0, '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª': 0}
        pred_counts = {'–ó–∞': 0, '–ü—Ä–æ—Ç–∏–≤': 0, '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è': 0, '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª': 0, '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª': 0}

        predictions_flat = predictions.flatten() if hasattr(predictions, 'flatten') else predictions

        for idx in range(len(X)):
            if 'vote' in y.columns:
                real_vote_code = int(y.iloc[idx]['vote'])
            else:
                real_vote_code = int(y.iloc[idx, -1])

            real_vote = vote_classes[real_vote_code]
            predicted_class = int(predictions_flat[idx])
            predicted_vote = vote_classes[predicted_class]
            confidence = float(probabilities[idx, predicted_class]) * 100
            is_correct = real_vote == predicted_vote

            real_counts[real_vote] += 1
            pred_counts[predicted_vote] += 1

            results.append({
                'name': fio_list[idx],
                'faction': faction_list[idx],
                'real_vote': real_vote,
                'real_vote_code': real_vote_code,
                'predicted_vote': predicted_vote,
                'predicted_vote_code': predicted_class,
                'confidence': round(confidence, 1),
                'is_correct': is_correct
            })

        total = len(results)
        correct = sum(1 for r in results if r['is_correct'])
        accuracy = (correct / total * 100) if total > 0 else 0

        real_passed = real_counts['–ó–∞'] >= 226
        pred_passed = pred_counts['–ó–∞'] >= 226

        return jsonify({
            'success': True,
            'deputies': results,
            'total': total,
            'correct': correct,
            'accuracy': round(accuracy, 2),
            'real_counts': real_counts,
            'pred_counts': pred_counts,
            'real_passed': real_passed,
            'pred_passed': pred_passed
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ predict_all: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/simulate', methods=['POST'])
def simulate_voting():
    if not MODEL_LOADED or not PANDAS_LOADED:
        return jsonify({'success': False, 'error': '–ú–æ–¥–µ–ª—å –∏–ª–∏ Pandas –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}), 503

    try:
        import pickle

        data = request.get_json()

        print("=" * 60)
        print("üì• –ü–æ–ª—É—á–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        for k, v in data.items():
            print(f"   {k}: {v} (—Ç–∏–ø: {type(v).__name__})")
        print("=" * 60)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–µ–ø—É—Ç–∞—Ç–æ–≤
        deputies_df = pd.read_csv('../data/for_interact_when_user_chooses.csv')

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –§–ò–û –∏ —Ñ—Ä–∞–∫—Ü–∏–∏
        fio_list = deputies_df['fio'].tolist()
        faction_list = deputies_df['fr_8'].tolist()

        # –£–¥–∞–ª—è–µ–º –§–ò–û –∏ —Ñ—Ä–∞–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features_df = deputies_df.drop(columns=['fio', 'fr_8'])

        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç –º–æ–¥–µ–ª—å)
        expected_columns = features_df.columns.tolist()
        print(f"‚úÖ –û–∂–∏–¥–∞–µ–º—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫: {len(expected_columns)} —à—Ç")

        # ============================================
        # –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò - –∫–æ–¥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ encoder
        # ============================================
        categorical_features = [
            'mainExecutives',
            'rubric',
            'type',
            'initiators_sort',
            'ammendments_authors_sorted',
            'meta_type_name_eng'
        ]

        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è (423 —Å—Ç—Ä–æ–∫–∏ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏)
        cat_values = {}
        for col in categorical_features:
            if col in data:
                cat_values[col] = [data[col]] * len(features_df)
            else:
                cat_values[col] = ['x'] * len(features_df)  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        cat_df = pd.DataFrame(cat_values)
        print(f"üìã –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è:")
        for col in categorical_features:
            print(f"   {col}: '{cat_df[col].iloc[0]}'")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º CatBoostEncoder –∏ –∫–æ–¥–∏—Ä—É–µ–º
        try:
            encoder_path = 'CatBoostEncoder_for_case_5.pkl'
            with open(encoder_path, 'rb') as f:
                catboost_encoder = pickle.load(f)
            print(f"‚úÖ CatBoostEncoder –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {encoder_path}")

            # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            encoded_values = catboost_encoder.transform(cat_df)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
            encoded_df = pd.DataFrame(
                encoded_values,
                columns=categorical_features,
                index=features_df.index
            )

            print(f"‚úÖ –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
            for col in categorical_features:
                print(f"   {col}: {encoded_df[col].iloc[0]:.6f}")

            # –ó–ê–ú–ï–ù–Ø–ï–ú –∑–Ω–∞—á–µ–Ω–∏—è –≤ features_df (–Ω–µ —É–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏!)
            for col in categorical_features:
                features_df[col] = encoded_df[col].values

        except FileNotFoundError:
            print(f"‚ö†Ô∏è {encoder_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—Å—Ä–µ–¥–Ω–∏–µ)
            for col in categorical_features:
                features_df[col] = 1.7  # –ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ encoder: {e}")
            import traceback
            traceback.print_exc()
            for col in categorical_features:
                features_df[col] = 1.7

        # ============================================
        # –ö–û–õ–ò–ß–ï–°–¢–í–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        # ============================================

        # N_initiators (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω–∏—Ü–∏–∞—Ç–æ—Ä–æ–≤)
        n_init = float(data.get('N_initiators', 10))
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: (x - mean) / std
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: mean ~= 30, std ~= 50
        n_init_normalized = (n_init - 30) / 50
        features_df['N_initiators'] = n_init_normalized
        print(f"‚úÖ N_initiators: {n_init} -> {n_init_normalized:.4f} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ)")

        # law_circ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—Ä–∞–≤–æ–∫)
        law_circ = float(data.get('law_circ', 200))
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: mean ~= 500, std ~= 800
        law_circ_normalized = (law_circ - 500) / 800
        features_df['law_circ'] = law_circ_normalized
        print(f"‚úÖ law_circ: {law_circ} -> {law_circ_normalized:.4f} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ)")

        # Session - —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—É—é
        session = float(data.get('Session', 4))
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: mean ~= 4, std ~= 2
        session_normalized = (session - 4) / 2
        features_df['Session'] = session_normalized
        print(f"‚úÖ Session: {session} -> {session_normalized:.4f} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ)")

        # ============================================
        # –ü–†–û–í–ï–†–Ø–ï–ú –ü–û–†–Ø–î–û–ö –ö–û–õ–û–ù–û–ö
        # ============================================
        features_df = features_df[expected_columns]
        print(f"‚úÖ –ü–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {len(features_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")

        # ============================================
        # –î–ï–õ–ê–ï–ú –ü–†–û–ì–ù–û–ó
        # ============================================

        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –Ω—É–ª—è–º–∏ (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        features_df = features_df.fillna(0)

        predictions = model.predict(features_df.values)
        probabilities = model.predict_proba(features_df.values)

        vote_classes = ['–ó–∞', '–ü—Ä–æ—Ç–∏–≤', '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è', '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª', '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª']

        results = []
        vote_counts = {'–ó–∞': 0, '–ü—Ä–æ—Ç–∏–≤': 0, '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è': 0, '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª': 0, '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª': 0}
        faction_votes = {}

        predictions_flat = predictions.flatten() if hasattr(predictions, 'flatten') else predictions

        for i in range(len(predictions_flat)):
            predicted_class = int(predictions_flat[i])
            vote = vote_classes[predicted_class]

            confidence = float(probabilities[i, predicted_class]) * 100
            probs_dict = {vote_classes[j]: round(float(probabilities[i, j]) * 100, 1) for j in range(len(vote_classes))}

            vote_counts[vote] += 1

            faction = faction_list[i]
            if faction not in faction_votes:
                faction_votes[faction] = {v: 0 for v in vote_classes}
            faction_votes[faction][vote] += 1

            results.append({
                'name': fio_list[i],
                'faction': faction,
                'vote': vote,
                'confidence': round(confidence, 1),
                'probabilities': probs_dict
            })

        total_za = vote_counts['–ó–∞']
        passed = total_za >= 226

        print("=" * 60)
        print(f"üó≥Ô∏è –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–ò–ú–£–õ–Ø–¶–ò–ò:")
        for vote_type, count in vote_counts.items():
            print(f"   {vote_type}: {count}")
        print(f"   –ò–¢–û–ì–û '–ó–∞': {total_za} / 226 –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ")
        print(f"   –†–ï–®–ï–ù–ò–ï: {'‚úÖ –ü–†–ò–ù–Ø–¢' if passed else '‚ùå –ù–ï –ü–†–ò–ù–Ø–¢'}")
        print("=" * 60)

        return jsonify({
            'success': True,
            'passed': passed,
            'vote_counts': vote_counts,
            'faction_votes': faction_votes,
            'deputies': results,
            'total_deputies': len(results)
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–º—É–ª—è—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


# ============================================
# ENDPOINTS –î–õ–Ø –ö–ï–ô–°–ê 3
# ============================================

@app.route('/api/votings_list', methods=['GET'])
def get_votings_list():
    votings = [
        {'id': '94008', 'date': '08.04.2016', 'name': '–ü–µ—Ä–≤–æ–µ —á—Ç–µ–Ω–∏–µ', 'has_predictions': True},
        {'id': '94108', 'date': '08.01.2016', 'name': '–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ 94108', 'has_predictions': False},
        {'id': '121108', 'date': '08.11.2016', 'name': '–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ 121108', 'has_predictions': False},
        {'id': '121208', 'date': '08.12.2016', 'name': '–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ 121208', 'has_predictions': False},
        {'id': '121308', 'date': '08.01.2017', 'name': '–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ 121308', 'has_predictions': False},
        {'id': '121408', 'date': '08.02.2017', 'name': '–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ 121408', 'has_predictions': False},
        {'id': '121508', 'date': '08.03.2017', 'name': '–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ 121508', 'has_predictions': False}
    ]
    return jsonify({'success': True, 'votings': votings})


@app.route('/api/predict_voting/<voting_id>', methods=['POST'])
def predict_voting(voting_id):
    if not MODEL_LOADED or not PANDAS_LOADED:
        return jsonify({'success': False, 'error': '–ú–æ–¥–µ–ª—å –∏–ª–∏ Pandas –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}), 503

    try:
        X_path = f'../data/X_2273_{voting_id}.csv'
        y_path = f'../data/y_2273_{voting_id}.csv'

        print(f"üîç –ò—â—É —Ñ–∞–π–ª—ã:")
        print(f"   X: {X_path}")
        print(f"   y: {y_path}")

        if not os.path.exists(X_path):
            return jsonify({'success': False, 'error': f'–§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {X_path}'}), 404

        if not os.path.exists(y_path):
            return jsonify({'success': False, 'error': f'–§–∞–π–ª –≥–æ–ª–æ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {y_path}'}), 404

        X_df = pd.read_csv(X_path)
        y_df = pd.read_csv(y_path)

        fio_list = X_df['fio'].tolist()
        faction_list = X_df['fr_8'].tolist()

        X_features = X_df.drop(columns=['fio', 'fr_8']).fillna(0)

        predictions = model.predict(X_features.values)
        probabilities = model.predict_proba(X_features.values)

        vote_dict = {0: '–í–æ–∑–¥–µ—Ä–∂–∞–ª—Å—è', 1: '–ó–∞', 2: '–ù–µ –≥–æ–ª–æ—Å–æ–≤–∞–ª', 3: '–û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª', 4: '–ü—Ä–æ—Ç–∏–≤'}

        if 'vote' in y_df.columns:
            real_votes_codes = y_df['vote'].astype(int).tolist()
        else:
            real_votes_codes = y_df.iloc[:, -1].astype(int).tolist()

        real_votes_text = [vote_dict.get(code, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') for code in real_votes_codes]

        results = []
        real_counts = {v: 0 for v in vote_dict.values()}
        pred_counts = {v: 0 for v in vote_dict.values()}
        correct_count = 0

        predictions_flat = predictions.flatten() if hasattr(predictions, 'flatten') else predictions

        for i in range(len(fio_list)):
            predicted_code = int(predictions_flat[i])
            predicted_vote = vote_dict[predicted_code]
            real_vote = real_votes_text[i]

            if real_vote in real_counts:
                real_counts[real_vote] += 1
            else:
                if '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ' not in real_counts:
                    real_counts['–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'] = 0
                    pred_counts['–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'] = 0
                real_counts['–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'] += 1
                real_vote = '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'

            pred_counts[predicted_vote] += 1

            confidence = float(probabilities[i, predicted_code]) * 100
            is_correct = (predicted_vote == real_vote)

            if is_correct:
                correct_count += 1

            results.append({
                'fio': fio_list[i],
                'faction': faction_list[i],
                'real_vote': real_vote,
                'predicted_vote': predicted_vote,
                'confidence': round(confidence, 1),
                'is_correct': is_correct
            })

        total = len(results)
        accuracy = (correct_count / total * 100) if total > 0 else 0

        real_passed = real_counts.get('–ó–∞', 0) >= 226
        pred_passed = pred_counts.get('–ó–∞', 0) >= 226

        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total} –¥–µ–ø—É—Ç–∞—Ç–æ–≤, —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2f}%")

        metrics = {}
        if SKLEARN_LOADED:
            try:
                precision, recall, f1, support = precision_recall_fscore_support(
                    real_votes_codes, predictions_flat, labels=list(vote_dict.keys()), zero_division=0
                )

                for i, (code, name) in enumerate(vote_dict.items()):
                    metrics[name] = {
                        'precision': round(float(precision[i]), 3),
                        'recall': round(float(recall[i]), 3),
                        'f1': round(float(f1[i]), 3),
                        'support': int(support[i])
                    }
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–µ—Ç—Ä–∏–∫: {e}")

        return jsonify({
            'success': True,
            'voting_id': voting_id,
            'deputies': results,
            'statistics': {
                'total': total,
                'correct': correct_count,
                'accuracy': round(accuracy, 2),
                'real_counts': real_counts,
                'pred_counts': pred_counts,
                'real_passed': real_passed,
                'pred_passed': pred_passed
            },
            'metrics': metrics
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ predict_voting: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


# ============================================
# ENDPOINTS –î–õ–Ø –ö–ï–ô–°–ê 2: –°–ï–¢–ï–í–û–ô –ì–†–ê–§
# ============================================

# –ú–∞–ø–ø–∏–Ω–≥ –ö–í–≠–î –≤ –∫—Ä—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
ACTIVITY_MAPPING = {
    '–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —Ç–∞ —Ç–µ–ª–µ–∫–æ–º—É–Ω—ñ–∫–∞—Ü—ñ—ó': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è',
    '–ü—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∞, –Ω–∞—É–∫–æ–≤–∞ —Ç–∞ —Ç–µ—Ö–Ω—ñ—á–Ω–∞ –¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å': '–ù–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä—Å–∫–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    '–§—ñ–Ω–∞–Ω—Å–æ–≤–∞ —Ç–∞ —Å—Ç—Ä–∞—Ö–æ–≤–∞ –¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å': '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –∏ —Å—Ç—Ä–∞—Ö–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    '–û–ø–µ—Ä–∞—Ü—ñ—ó –∑ –Ω–µ—Ä—É—Ö–æ–º–∏–º –º–∞–π–Ω–æ–º': '–û–ø–µ—Ä–∞—Ü–∏–∏ —Å –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å—é',
    '–ü–µ—Ä–µ—Ä–æ–±–Ω–∞ –ø—Ä–æ–º–∏—Å–ª–æ–≤—ñ—Å—Ç—å': '–ü–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∞—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç—å',
    '–°—ñ–ª—å—Å—å–∫–µ –≥–æ—Å–ø–æ–¥–∞—Ä—Å—Ç–≤–æ, –ª—ñ—Å–æ–≤–µ –≥–æ—Å–ø–æ–¥–∞—Ä—Å—Ç–≤–æ —Ç–∞ —Ä–∏–±–Ω–µ –≥–æ—Å–ø–æ–¥–∞—Ä—Å—Ç–≤–æ': '–°–µ–ª—å—Å–∫–æ–µ —Ö–æ–∑—è–π—Å—Ç–≤–æ',
    '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç, —Å–∫–ª–∞–¥—Å—å–∫–µ –≥–æ—Å–ø–æ–¥–∞—Ä—Å—Ç–≤–æ, –ø–æ—à—Ç–æ–≤–∞ —Ç–∞ –∫—É—Ä\'—î—Ä—Å—å–∫–∞ –¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞',
    '–ë—É–¥—ñ–≤–Ω–∏—Ü—Ç–≤–æ': '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ',
    '–û–ø—Ç–æ–≤–∞ —Ç–∞ —Ä–æ–∑–¥—Ä—ñ–±–Ω–∞ —Ç–æ—Ä–≥—ñ–≤–ª—è; —Ä–µ–º–æ–Ω—Ç –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∏—Ö –∑–∞—Å–æ–±—ñ–≤ —ñ –º–æ—Ç–æ—Ü–∏–∫–ª—ñ–≤': '–¢–æ—Ä–≥–æ–≤–ª—è',
    '–ù–∞–¥–∞–Ω–Ω—è —ñ–Ω—à–∏—Ö –≤–∏–¥—ñ–≤ –ø–æ—Å–ª—É–≥': '–ü—Ä–æ—á–∏–µ —É—Å–ª—É–≥–∏',
    '–î—ñ—è–ª—å–Ω—ñ—Å—Ç—å —É —Å—Ñ–µ—Ä—ñ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Ç–∞ –¥–æ–ø–æ–º—ñ–∂–Ω–æ–≥–æ –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è': '–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —É—Å–ª—É–≥–∏',
}

SPECIALIZATION_KEYWORDS = {
    '–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω—ñ —Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è',
    '–¢–ï–ö': '–¢–≠–ö',
    '–µ–Ω–µ—Ä–≥–µ—Ç–∏–∫': '–¢–≠–ö',
    '–≥–∞–∑': '–¢–≠–ö',
    '–Ω–∞—Ñ—Ç': '–¢–≠–ö',
    '–ø–∞–ª–∏–≤–æ': '–¢–≠–ö',
    '–§–∏–Ω–∞–Ω—Å': '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –∏ —Å—Ç—Ä–∞—Ö–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    '—Å—Ç—Ä–∞—Ö–æ–≤': '–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –∏ —Å—Ç—Ä–∞—Ö–æ–≤–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
    '–°—ñ–ª—å—Å—å–∫–µ': '–°–µ–ª—å—Å–∫–æ–µ —Ö–æ–∑—è–π—Å—Ç–≤–æ',
    '–∑–µ—Ä–Ω–æ–≤': '–°–µ–ª—å—Å–∫–æ–µ —Ö–æ–∑—è–π—Å—Ç–≤–æ',
    '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞',
    '–ì–æ—Å—É–ø—Ä–∞–≤': '–ì–æ—Å—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ',
}


def map_activity(activity):
    if not PANDAS_LOADED or pd.isna(activity) or activity == '':
        return '–ù–µ —É–∫–∞–∑–∞–Ω–∞'

    if activity in ACTIVITY_MAPPING:
        return ACTIVITY_MAPPING[activity]

    for keyword, category in SPECIALIZATION_KEYWORDS.items():
        if keyword.lower() in str(activity).lower():
            return category

    return activity[:40] if len(str(activity)) > 40 else str(activity)


def calculate_graph_stats(nodes, edges):
    nodes_count = len(nodes)
    edges_count = len(edges)

    if nodes_count > 0:
        avg_degree = round(sum(n['degree'] for n in nodes) / nodes_count, 2)
    else:
        avg_degree = 0

    max_edges = nodes_count * (nodes_count - 1) / 2
    density = round(edges_count / max_edges, 3) if max_edges > 0 else 0

    return {
        'nodes_count': nodes_count,
        'edges_count': edges_count,
        'avg_degree': avg_degree,
        'density': density
    }


def build_graph_from_dataframe(df):
    nodes = []
    edges = []

    deputy_region_count = defaultdict(lambda: defaultdict(int))
    deputy_activity_count = defaultdict(lambda: defaultdict(int))
    region_activity_count = defaultdict(lambda: defaultdict(int))

    for idx, row in df.iterrows():
        deputy = row['full_name']
        region = row['obl']
        activity = row['activity']

        if pd.isna(deputy) or pd.isna(region) or pd.isna(activity):
            continue

        activity_mapped = map_activity(activity)

        deputy_region_count[deputy][region] += 1
        deputy_activity_count[deputy][activity_mapped] += 1
        region_activity_count[region][activity_mapped] += 1

    deputy_ids = {}
    for deputy in deputy_region_count.keys():
        deputy_id = f"dep_{len(deputy_ids)}"
        deputy_ids[deputy] = deputy_id

        total_companies = sum(deputy_region_count[deputy].values())

        nodes.append({
            'id': deputy_id,
            'label': deputy,
            'type': 'deputy',
            'degree': 0,
            'data': {'companies_count': total_companies}
        })

    region_ids = {}
    for deputy in deputy_region_count:
        for region in deputy_region_count[deputy]:
            if region not in region_ids:
                region_id = f"reg_{len(region_ids)}"
                region_ids[region] = region_id

                nodes.append({
                    'id': region_id,
                    'label': region,
                    'type': 'region',
                    'degree': 0,
                    'data': {}
                })

    activity_ids = {}
    all_activities = set()
    for activities in deputy_activity_count.values():
        all_activities.update(activities.keys())
    for activities in region_activity_count.values():
        all_activities.update(activities.keys())

    for activity in all_activities:
        if activity and activity != 'nan' and activity != '–ù–µ —É–∫–∞–∑–∞–Ω–∞':
            activity_id = f"act_{len(activity_ids)}"
            activity_ids[activity] = activity_id

            nodes.append({
                'id': activity_id,
                'label': activity,
                'type': 'activity',
                'degree': 0,
                'data': {}
            })

    edge_id = 0

    for deputy, regions in deputy_region_count.items():
        for region, count in regions.items():
            if count > 0:
                edges.append({
                    'id': f'e{edge_id}',
                    'source': deputy_ids[deputy],
                    'target': region_ids[region],
                    'weight': count,
                    'label': f'{count}'
                })
                edge_id += 1

    for region, activities in region_activity_count.items():
        for activity, count in activities.items():
            if count > 0 and activity in activity_ids:
                edges.append({
                    'id': f'e{edge_id}',
                    'source': region_ids[region],
                    'target': activity_ids[activity],
                    'weight': count,
                    'label': f'{count}'
                })
                edge_id += 1

    for deputy, activities in deputy_activity_count.items():
        for activity, count in activities.items():
            if count > 0 and activity in activity_ids:
                edges.append({
                    'id': f'e{edge_id}',
                    'source': deputy_ids[deputy],
                    'target': activity_ids[activity],
                    'weight': count,
                    'label': f'{count}'
                })
                edge_id += 1

    degree_count = defaultdict(int)
    for edge in edges:
        degree_count[edge['source']] += 1
        degree_count[edge['target']] += 1

    for node in nodes:
        node['degree'] = degree_count[node['id']]

    return nodes, edges


@app.route('/api/deputies/list', methods=['GET'])
def get_deputies_list():
    if not PANDAS_LOADED:
        return jsonify({'success': False, 'error': 'Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}), 500

    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))

        possible_paths = [
            os.path.join(current_dir, 'data', 'example_Skr_Khom__3_.csv'),
            os.path.join(current_dir, '..', 'data', 'example_Skr_Khom__3_.csv'),
            'data/example_Skr_Khom__3_.csv',
            '../data/example_Skr_Khom__3_.csv',
            'example_Skr_Khom__3_.csv'
        ]

        csv_path = None
        for path in possible_paths:
            full_path = os.path.abspath(path)
            print(f"üîç –ü—Ä–æ–≤–µ—Ä—è—é –ø—É—Ç—å: {full_path}")
            if os.path.exists(full_path):
                csv_path = full_path
                print(f"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {csv_path}")
                break

        if not csv_path:
            searched_paths = '\n'.join([os.path.abspath(p) for p in possible_paths])
            return jsonify({
                'success': False,
                'error': f'CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–∫–∞–ª –≤:\n{searched_paths}\n\n–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}'
            }), 404

        df = pd.read_csv(csv_path)

        if 'full_name' not in df.columns:
            return jsonify({
                'success': False,
                'error': f'–í CSV —Ñ–∞–π–ª–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ "full_name". –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}'
            }), 400

        deputies = df['full_name'].dropna().unique().tolist()

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(deputies)} –¥–µ–ø—É—Ç–∞—Ç–æ–≤")

        return jsonify({
            'success': True,
            'deputies': deputies
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ get_deputies_list: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/graph/real/<deputy_name>', methods=['GET'])
def get_real_graph(deputy_name):
    if not PANDAS_LOADED:
        return jsonify({'success': False, 'error': 'Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}), 500

    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))

        possible_paths = [
            os.path.join(current_dir, 'data', 'example_Skr_Khom__3_.csv'),
            os.path.join(current_dir, '..', 'data', 'example_Skr_Khom__3_.csv'),
            'data/example_Skr_Khom__3_.csv',
            '../data/example_Skr_Khom__3_.csv',
            'example_Skr_Khom__3_.csv'
        ]

        csv_path = None
        for path in possible_paths:
            full_path = os.path.abspath(path)
            if os.path.exists(full_path):
                csv_path = full_path
                break

        if not csv_path:
            return jsonify({'success': False, 'error': 'CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404

        df = pd.read_csv(csv_path)

        if deputy_name == 'all':
            deputy_df = df
        else:
            deputy_df = df[df['full_name'].str.contains(deputy_name, na=False, case=False)]

        if deputy_df.empty:
            return jsonify({'success': False, 'error': f'–î–µ–ø—É—Ç–∞—Ç {deputy_name} –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(deputy_df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–µ–ø—É—Ç–∞—Ç–∞ {deputy_name}")

        nodes, edges = build_graph_from_dataframe(deputy_df)
        stats = calculate_graph_stats(nodes, edges)

        return jsonify({
            'success': True,
            'nodes': nodes,
            'edges': edges,
            'stats': stats
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ get_real_graph: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/graph/coauthorship', methods=['GET'])
def get_coauthorship_graph():
    if not PANDAS_LOADED:
        return jsonify({'success': False, 'error': 'Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}), 500

    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))

        possible_paths = [
            os.path.join(current_dir, 'data', 'example_Skr_Khom__3_.csv'),
            os.path.join(current_dir, '..', 'data', 'example_Skr_Khom__3_.csv'),
            'data/example_Skr_Khom__3_.csv',
            '../data/example_Skr_Khom__3_.csv',
            'example_Skr_Khom__3_.csv'
        ]

        csv_path = None
        for path in possible_paths:
            full_path = os.path.abspath(path)
            if os.path.exists(full_path):
                csv_path = full_path
                break

        if not csv_path:
            return jsonify({'success': False, 'error': 'CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 404

        df = pd.read_csv(csv_path)

        deputy_activities = defaultdict(set)

        for idx, row in df.iterrows():
            deputy = row['full_name']
            activity = map_activity(row['activity'])

            if pd.notna(deputy) and activity != '–ù–µ —É–∫–∞–∑–∞–Ω–∞':
                deputy_activities[deputy].add(activity)

        nodes = []
        deputy_ids = {}

        for deputy, activities in deputy_activities.items():
            deputy_id = f"dep_{len(deputy_ids)}"
            deputy_ids[deputy] = deputy_id

            nodes.append({
                'id': deputy_id,
                'label': deputy,
                'type': 'deputy',
                'degree': 0,
                'data': {'activities_count': len(activities)}
            })

        edges = []
        edge_id = 0
        deputies_list = list(deputy_activities.keys())

        for i in range(len(deputies_list)):
            for j in range(i + 1, len(deputies_list)):
                dep1 = deputies_list[i]
                dep2 = deputies_list[j]

                common_activities = deputy_activities[dep1] & deputy_activities[dep2]

                if len(common_activities) > 0:
                    edges.append({
                        'id': f'e{edge_id}',
                        'source': deputy_ids[dep1],
                        'target': deputy_ids[dep2],
                        'weight': len(common_activities),
                        'label': f'{len(common_activities)} –æ–±—â–∏—Ö'
                    })
                    edge_id += 1

        degree_count = defaultdict(int)
        for edge in edges:
            degree_count[edge['source']] += 1
            degree_count[edge['target']] += 1

        for node in nodes:
            node['degree'] = degree_count[node['id']]

        stats = calculate_graph_stats(nodes, edges)

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω –≥—Ä–∞—Ñ —Å–æ–∞–≤—Ç–æ—Ä—Å—Ç–≤–∞: {len(nodes)} —É–∑–ª–æ–≤, {len(edges)} —Ä—ë–±–µ—Ä")

        return jsonify({
            'success': True,
            'nodes': nodes,
            'edges': edges,
            'stats': stats
        })

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ get_coauthorship_graph: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500


# ============================================
# MAIN
# ============================================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5001))
    app.run(host='0.0.0.0', port=port, debug=False)